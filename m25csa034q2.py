# -*- coding: utf-8 -*-
"""m25csa034q2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f1kZck6GeVHfozPO8w_fkDEZ_VS-EIMW
"""

!pip -q install datasets torchvision transformers huggingface_hub wandb scikit-learn matplotlib

from huggingface_hub import notebook_login
notebook_login()

import wandb
wandb.login()

#load cifar dataset
from datasets import load_dataset

dataset = load_dataset("Chiranjeev007/CIFAR-10_Subset")

train_hf = dataset["train"]
val_hf   = dataset["validation"]
test_hf  = dataset["test"]

print(len(train_hf), len(val_hf), len(test_hf))

#creating the dataloader by applying various transformations
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader

train_transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(0.2,0.2,0.2,0.1),
    transforms.ToTensor(),
    transforms.Normalize((0.5,)*3,(0.5,)*3)
])

test_transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,)*3,(0.5,)*3)
])

class CIFAR10Dataset(Dataset):
    def __init__(self, hf_ds, transform=None):
        self.ds = hf_ds
        self.transform = transform

    def __len__(self):
        return len(self.ds)

    def __getitem__(self, idx):
        img = self.ds[idx]["image"]
        label = self.ds[idx]["label"]
        if self.transform:
            img = self.transform(img)
        return img, label

train_ds = CIFAR10Dataset(train_hf, train_transform)
val_ds   = CIFAR10Dataset(val_hf, test_transform)
test_ds  = CIFAR10Dataset(test_hf, test_transform)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
val_loader   = DataLoader(val_ds, batch_size=32)
test_loader  = DataLoader(test_ds, batch_size=32)

"""#model training"""

#load pre trained resnet 18
import torch
import torch.nn as nn
from torchvision.models import resnet18

device = "cuda" if torch.cuda.is_available() else "cpu"

model = resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features,10)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(),lr=3e-4)

wandb.init(project="cifar10-mlops")

#training loop
def run_epoch(loader,train=True):
    if train: model.train()
    else: model.eval()

    loss_total,correct,total=0,0,0

    for x,y in loader:
        x,y=x.to(device),y.to(device)

        if train: optimizer.zero_grad()
        out=model(x)
        loss=criterion(out,y)

        if train:
            loss.backward()
            optimizer.step()

        loss_total+=loss.item()
        correct+=(out.argmax(1)==y).sum().item()
        total+=y.size(0)

    return loss_total/len(loader),correct/total

best_val=0
for epoch in range(5):
    tr_loss,tr_acc=run_epoch(train_loader,True)
    val_loss,val_acc=run_epoch(val_loader,False)

    wandb.log({"train_loss":tr_loss,"val_loss":val_loss,
               "train_acc":tr_acc,"val_acc":val_acc})

    if val_acc>best_val:
        best_val=val_acc
        torch.save(model.state_dict(),"best_model.pth")

    print(epoch,tr_acc,val_acc)

from huggingface_hub import create_repo, upload_file

repo_id = "sandesh2233/cifar10-resnet18"

# create repo
create_repo(repo_id, exist_ok=True)

# upload model
upload_file(
    path_or_fileobj="best_model.pth",
    path_in_repo="best_model.pth",
    repo_id=repo_id
)

from huggingface_hub import hf_hub_download
import torch

repo_id = "sandesh2233/cifar10-resnet18"

model_path = hf_hub_download(repo_id=repo_id, filename="best_model.pth")

model.load_state_dict(torch.load(model_path, map_location=device))
model.eval()

print("Model loaded from HuggingFace successfully")

from sklearn.metrics import confusion_matrix
import numpy as np

y_true=[]
y_pred=[]

for x,y in test_loader:
    x=x.to(device)
    pred=model(x).argmax(1).cpu().numpy()
    y_pred.extend(pred)
    y_true.extend(y.numpy())

print("Collected predictions")

cm=confusion_matrix(y_true,y_pred)

wandb.log({
    "confusion_matrix":
    wandb.plot.confusion_matrix(probs=None,y_true=y_true,preds=y_pred)
})

class_names=["airplane","auto","bird","cat","deer","dog","frog","horse","ship","truck"]

class_acc=cm.diagonal()/cm.sum(axis=1)

wandb.log({"class_accuracy":
wandb.plot.bar(
    wandb.Table(data=[[c,a] for c,a in zip(class_names,class_acc)],
    columns=["class","accuracy"]),
    "class","accuracy")
})

correct=[]
wrong=[]

for img,label in test_ds:
    pred=model(img.unsqueeze(0).to(device)).argmax().item()

    if pred==label and len(correct)<10:
        correct.append((img,label,pred))
    elif pred!=label and len(wrong)<10:
        wrong.append((img,label,pred))

    if len(correct)==10 and len(wrong)==10:
        break

wandb.log({"examples":[wandb.Image(img,caption=f"Pred:{p} True:{t}")
                       for img,t,p in correct+wrong]})

test_acc=(np.array(y_true)==np.array(y_pred)).mean()
print("Test Accuracy:",test_acc)

print("\nClass wise accuracy:")
for i,name in enumerate(class_names):
    print(name,":",class_acc[i])

